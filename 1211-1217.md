### Bilinear CNN Models for Fine-grained Visual Recognition

Bilinear 模型定义为：$\mathcal{B}=(f_A, f_B, \mathcal{P}, \mathcal{C})$，其中 $f_A$ 与 $f_B$ 分别为特征提取函数，$\mathcal{P}$ 为 Pooling 函数，$\mathcal{C}$ 表示分类函数。另外特征提取函数满足：

$$f~:~\mathcal{L}\times\mathcal{I} \rightarrow R^{c \times D}$$

其中 $I$ 表示图像，$L$ 表示位置（含缩放+位置信息），基于此，$f_A$ 与 $f_B$ 在位置 $l$ 的 Bilinear 特征表示为：$\text{bilinear}(l, \mathcal{I}, f_A, f_B) = f_A(l,  \mathcal{I})^T f_B(l, \mathcal{I})$。

接下来，就是需要寻找满足上面条件的相应函数了。

$f$ 这里用的是一个在 ImageNet 预训练的网络模型卷积层提取的特征，如 VGG19 等。

### Fully Convolutional Network for Semantic Segmentation

这篇论文是 15 年 CVPR 的最佳论文，提出了使用全卷积网络进行语义分割，并将分割结果提升了 20%，相当于是开辟了 CNN 在语义分割的这个方向。

论文核心要点其实比较简单，以 VGG16 为例，作者将最后一个全连接层换成 Conv2d + TransposedConv2d，最终输出的是与原图同尺寸的多通道结果。作者发现，直接将最后一层特征层结果连接到全卷积层上的时候，效果会有一定提升，将倒数第二层特征结果也连接到全卷积的时候，效果会更好，最终在论文中做了三个实验：fcn8, fcn16, fcn32。其实在 PyTorch 中实现也挺简单的。

```python
# fcn8
vgg16 = models.vgg16(pretrained=True)
feats = list(vgg16.features.children())

feats2 = nn.Sequential(*feats[0:9])
feats3 = nn.Sequential(*feats[10:16])
feats4 = nn.Sequential(*feats[17:23])
feats5 = nn.Sequential(*feats[24:30])

fconn  = nn.Sequential(
    nn.Conv2d(512, 4096, 7),
    nn.ReLU(inplace=True),
    nn.Dropout(),
    nn.Conv2d(4096, 4096, 1),
    nn.ReLU(inplace=True),
    nn.Dropout()    
)
 score_feat3 = nn.Conv2d(256, num_classes, 1)
 score_feat4 = nn.Conv2d(512, num_classes, 1)
 score_fconn = nn.Conv2d(4096, num_classes, 1)

## for forward pass (input is x)
feat2 = self.feats(x)
feat3 = self.feat3(feats)
feat4 = self.feat4(feat3)
feat5 = self.feat5(feat4)
fconn = self.fconn(feat5)

score_feat3 = self.score_feat3(feat3)
score_feat4 = self.score_feat4(feat4)
score_fconn = self.score_fconn(fconn)

score = F.upsample_bilinear(score_fconn, score_feat4.size()[2:])
score += score_feat4
score = F.upsample_bilinear(score, score_feat3.size()[2:])
score += score_feat3
# final output
F.upsample_bilinear(score, x.size()[2:])
```